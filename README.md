## Awesome-DL-Inference
This is a paper list about DNN inference.

### DNN Inference
[NSDI'17][UCB] [Clipper: A Low-Latency Online Prediction Serving System](https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/crankshaw)  
[SOSP'19][Amason] [Nexus: a GPU cluster engine for accelerating DNN-based video analysis](https://dl.acm.org/doi/abs/10.1145/3341301.3359658)  
[ATC'19][HKUST] [MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine Learning Inference Serving](https://www.usenix.org/conference/atc19/presentation/zhang-chengliang)  
[SoCC'20][UCR] [GSLICE: Controlled Spatial Sharing of GPUs for a Scalable Inference Platform](https://dl.acm.org/doi/abs/10.1145/3419111.3421284)  
[ATC'22][KAIST] [Serving Heterogeneous Machine Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing](https://www.usenix.org/conference/atc22/presentation/choi-seungbeom)  
[ATC'21][Stanford] [INFaaS: Automated Model-less Inference Serving](https://www.usenix.org/conference/atc21/presentation/romero)  


### LLM Inference
[OSDI'22][SNU] [ORCA: A Distributed Serving System for Transformer-Based Generative Models](https://www.usenix.org/conference/osdi22/presentation/yu)   
[arXiv'23][PKU] [Fast Distributed Inference Serving for Large Language Models](https://arxiv.org/abs/2305.05920)    
[SOSP'23][UCB] [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://dl.acm.org/doi/abs/10.1145/3600006.3613165) 

